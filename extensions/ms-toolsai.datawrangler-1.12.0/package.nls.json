{"command.dataWrangler.changeKernel.title":"Change selected runtime","command.dataWrangler.clearCachedKernel.title":"Clear cached runtime","command.dataWrangler.dataViewerClearSorts.title":{"message":"Clear sorts","comment":["Note that 'sorts' is referring to a series of sort (ordering of data) operations applied to a column. It does not mean 'classifications' or 'kinds'."]},"command.dataWrangler.dataViewerClearFilters.title":"Clear filters","command.dataWrangler.openInDataWrangler.title":"Open in Data Wrangler","command.dataWrangler.reportIssue.title":"Report issue","command.dataWrangler.applyOperation.title":"Apply step","command.dataWrangler.discardOperation.title":"Discard step","command.dataWrangler.previewOperation.title":{"message":"Perform operation","comment":["'operation' in the sense: an operation on a data table."]},"command.dataWrangler.undoOperation.title":"Undo step","command.dataWrangler.runPerformanceTests.title":"Run performance tests","command.dataWrangler.showTelemetryData.title":"Show telemetry data","command.dataWrangler.openSettings.title":"Data Wrangler Settings","command.dataWrangler.openExperiments.title":"Data Wrangler Experiments","command.dataWrangler.openFile.title":"Open File","command.dataWrangler.walkthroughCsv.title":{"message":"Open Walkthrough CSV file","comment":["A CSV (Comma-Separated Values) file has extension .csv and is a common file format for tabular data."]},"command.dataWrangler.openWalkthrough.title":"Open Walkthrough","command.dataWrangler.revealSourceFileInFileExplorer.title":"Reveal Source File in Explorer View","command.dataWrangler.openNotebookVariable.title":"View data","command.dataWrangler.openSourceFileInBasicEditor.title":{"message":"Open Source File in Basic Editor","comment":["'Source file' meaning the file (with CSV, TSV, Excel, etc. format) where the data table was opened from."]},"command.dataWrangler.launchDataViewer.title":"Launch in Data Wrangler","configuration.dataWrangler.startInEditModeForNotebookEntrypoints.description":"Opens data directly in editing mode when entering from a Jupyter notebook file.","configuration.dataWrangler.columnInsights.displayOnOpen.description":"Whether to display the column insights the moment a dataset is loaded.","configuration.dataWrangler.useRelativePath.description":{"message":"Enable path resolution for local files relative to the root directory of the connection. Note that this setting only applies to local interpreter connections.","comment":["'relative' path resolution is in contrast with one that uses a absolute path."]},"configuration.dataWrangler.debug.description":"Enable debugging features for troubleshooting the Data Wrangler extension.","configuration.dataWrangler.enabledFileTypes.description":{"message":"File extensions to offer to open with Data Wrangler.","comment":["Meaning: the file types for which Visual Studio Code will show the option to 'Open with Data Wrangler'.","'file extensions' in the sense of the suffix of a digital data file indicating its file format. E.g., .csv, .json, etc."]},"configuration.dataWrangler.enabledFileTypes.csv.description":"Comma-separated values","configuration.dataWrangler.enabledFileTypes.tsv.description":"Tab-separated values","configuration.dataWrangler.enabledFileTypes.parquet.description":{"message":"Apache Parquet","comment":["Parquet is the name of a file format for storing data tables. It was created by the Apache Software Foundation."]},"configuration.dataWrangler.enabledFileTypes.xlsx.description":"Excel workbook","configuration.dataWrangler.enabledFileTypes.xls.description":"Excel 97-2003 workbook","configuration.dataWrangler.enabledFileTypes.jsonl.description":{"message":"JSON Lines","comment":["JSON Lines is the name of a file format for storing data (.jsonl file extension). Each line of this file type contains a JSON object."]},"configuration.dataWrangler.experimentsTitle":"Experiments","configuration.dataWrangler.experiments.fastCsvParsing.markdownDescription":{"message":"**Experimental** enable fast CSV parsing using the PyArrow engine. Requires the `pyarrow` package and `pandas>=1.4.0`. [Read more about PyArrow support in Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#specifying-the-parser-engine).","comment":["{Locked=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#specifying-the-parser-engine\"}","This localization string uses Markdown syntax.","'CSV' meaning a CSV (Comma-Separated Values) file.","'package' meaning Python package."]},"configuration.dataWrangler.experiments.autoDetectCsvDelimiter.markdownDescription":{"message":"**Experimental** automatically detect the delimiter when opening CSV files.","comment":["This localization string uses Markdown syntax.","'Delimiter' meaning the character that separates fields in a CSV file, which is normally a comma, but can also be a semicolon, tab, etc."]},"configuration.dataWrangler.experiments.useJupyterProposedAPI.markdownDescription":{"message":"**Experimental** use proposed Jupyter extension APIs when opening Data Wrangler from a notebook (requires the pre-release version of the Jupyter extension for Visual Studio Code).","comment":["This localization string uses Markdown syntax.","'notebook' in the sense Jupyter notebook."]},"configuration.dataWrangler.experiments.datatypes.pyspark.markdownDescription":{"message":"**Experimental** allow loading from PySpark DataFrame variables.","comment":["This localization string uses Markdown syntax.","PySpark DataFrame is a data type from the PySpark Python library."]},"configuration.dataWrangler.experiments.copilot.enabled.markdownDescription":{"message":"**Experimental** enable Copilot powered features in Data Wrangler. Note that this feature requires both the [GitHub Copilot Chat VS Code extension](command:extension.open?%5B%22github.copilot-chat%22%5D) and having an active [Copilot Subscription](https://github.com/features/copilot).","comment":["'Copilot' refers to an AI assistant."]},"contributes.walkthroughs.dataWranglerWelcome.title":"Get started with Data Wrangler","contributes.walkthroughs.dataWranglerWelcome.description":"Start cleaning data with Pandas and Python in only a few steps.","contributes.walkthroughs.dataWranglerWelcome.steps.openDataWrangler.title":"Step 1: Open Data Wrangler","contributes.walkthroughs.dataWranglerWelcome.steps.openDataWrangler.description":{"message":"**From a Jupyter Notebook:** A button with the Data Wrangler logo should appear right above the output of code that displays dataframe, such as ``df.head()``. \n**From the file explorer of Visual Studio Code:** Right click a CSV file to open it with Data Wrangler.\n[Open file in Data Wrangler](command:dataWrangler.openFile)\nðŸ”Ž Check out our [docs](https://github.com/microsoft/vscode-data-wrangler) to learn more.","comment":["{Locked=\"command:dataWrangler.openFile\"}","{Locked=\"https://github.com/microsoft/vscode-data-wrangler\"}","This localization string uses Markdown syntax."]},"contributes.walkthroughs.dataWranglerWelcome.steps.openDataWrangler-web-variant.description":{"message":"**From a Jupyter Notebook:** A button with the Data Wrangler logo should appear right above the output of code that displays a dataframe, such as ``df.head()``. \nðŸ”Ž Check out our [docs](https://github.com/microsoft/vscode-data-wrangler) to learn more.","comment":["{Locked=\"https://github.com/microsoft/vscode-data-wrangler\"}"]},"contributes.walkthroughs.dataWranglerWelcome.steps.openDataWrangler.media.altText":"Entrypoints to Data Wrangler","contributes.walkthroughs.dataWranglerWelcome.steps.cleanDataUsingOperations.title":{"message":"Step 2: Clean data using operations","comment":["'operation' in the sense: an operation on a data table."]},"contributes.walkthroughs.dataWranglerWelcome.steps.cleanDataUsingOperations.description":{"message":"Browse the list of built-in data cleaning operations or write your own using the code editor. The data grid will update with a live preview of what changed.\nðŸ§ª **Tip:** Try out our [experiments](command:dataWrangler.openExperiments) to enable new features.","comment":["{Locked=\"command:dataWrangler.openExperiments\"}","This localization string uses Markdown syntax."]},"contributes.walkthroughs.dataWranglerWelcome.steps.cleanDataUsingOperations.media.altText":{"message":"Diff of a drop column operation","comment":["The operation is named 'Drop column' and it drops or deletes a column from a data table."]},"contributes.walkthroughs.dataWranglerWelcome.steps.applyYourChanges.title":"Step 3: Apply your changes","contributes.walkthroughs.dataWranglerWelcome.steps.applyYourChanges.description":"âœ” Review the generated code in the bottom code panel.\nâœ” Apply the operation to add it to your list of cleaning steps.\nâœ” Undo or edit your last operation in the \"Cleaning Steps\" panel.\nðŸ”Ž **Tip:** Try clicking \"Preview code for all steps\" in the Cleaning Steps panel.","contributes.walkthroughs.dataWranglerWelcome.steps.applyYourChanges.media.altText":"Operation committed","contributes.walkthroughs.dataWranglerWelcome.steps.exportYourCode.title":"Step 4: Export your code or data","contributes.walkthroughs.dataWranglerWelcome.steps.exportYourCode.description":"At the top, you'll find buttons to export all the code back to your notebook, create a script or save the clean data as a CSV.","contributes.walkthroughs.dataWranglerWelcome.steps.exportYourCode.media.altText":"Export back to notebook","contributes.walkthroughs.dataWranglerWelcome.steps.openTitanicCSV.title":{"message":"Try with the Titanic dataset","comment":["The Titanic dataset is a dataset containing information about passengers of the Titanic ship, and whether they survived or not after its sinking. It is a common dataset used for data analysis and machine learning tasks."]},"contributes.walkthroughs.dataWranglerWelcome.steps.openTitanicCSV.description":{"message":"Try Data Wrangler with the Titanic dataset from Kaggle\n[Open the Titanic dataset](command:dataWrangler.walkthroughCsv)\nðŸ”Ž Check out our [docs](https://github.com/microsoft/vscode-data-wrangler) to learn more.","comment":["{Locked=\"Kaggle\"}","{Locked=\"command:dataWrangler.walkthroughCsv\"}","{Locked=\"https://github.com/microsoft/vscode-data-wrangler\"}","The Titanic dataset is a dataset containing information about passengers on the famous Titanic ship, and whether they survived or not after its sinking. It is a common dataset used for data analysis and machine learning tasks."]},"contributes.walkthroughs.dataWranglerWelcome.steps.openTitanicCSV.media.altText":{"message":"Open the Titanic dataset","comment":["The Titanic dataset is a dataset containing information about passengers on the famous Titanic ship, and whether they survived or not after its sinking. It is a common dataset used for data analysis and machine learning tasks."]}}
